{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **ECS7020P Mini-Project**\n",
        "\n",
        "\n",
        "### **Advanced component**"
      ],
      "metadata": {
        "id": "eafRwj4j1MYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Author:** Sayali Vijay Ghodke\n",
        "### **Student ID:** 230692620"
      ],
      "metadata": {
        "id": "Roq8JBmP1VFO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Problem Formulation**\n",
        "\n",
        "In this problem statement, we predict whether the particular dish is made at home or at a restaurant based on the ingredients of the dish. In this, we will be considering the ingredients as the input and classify the dish as **\"Homemade\"** or **\"Restaurant\"**.\n",
        "\n",
        "As we know, there are certain ingredients that are usually not available at Home but always available in a Restaurant, so we have considered this problem statement in order to determine whether the dish is made with the ingredients available at home or the dish is made at a restaurant.\n",
        "\n",
        "This will be helpfull in a real life scenario where we can detemine whether a dish can be made at home or not.\n"
      ],
      "metadata": {
        "id": "LHnx-YoC12Oo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning Pipline:\n",
        "\n",
        "### 1. Input Format:\n",
        "\n",
        "We will be considering the attributes dataset for this problem statement. As we need to classify that the dish is **\"Homemade\"** or **\"Restaurant_Made\"**, we will need to focus on two columns **\"Ingredients\"**  and **\"Home_or_restaurant\"**. In the CSV file **\"MLEndYD_image_attributes_benchmark.csv\"** we have various columns such as **filename** (which is nothing but the names of the images), **Diet** (this column is a drop down option which has three options, Vegetarian, Non-vegetarian,\n",
        "or Vegan), **Cuisine_org** (which contains the region of origin of the dish), Cuisine (this columns contains the name of the country in which the corresponding dish is a speciality), **Dish_name** (which contains names of the dishes that corresponds to the image), **Home_or_restaurant** (which states whether the corresponding dish is made at home or any restaurant, who's name is specified), **Ingredients** (it contains the basic ingredients that are used to make that specific dish), **Healthiness_rating** (this column is also drop down option which has, Very healthy, Healthy, Neutral, Unhealthy, Very unhealthy, which will decribe the healthyness of the dish)**Healthiness_rating_int** (this column contains the integer value for categorical values in Healthiness_rating column), **Likeness** (this is also a drop down column which will tell us about the likelihood of that dish based on a random person and it has, Strongly like, Like, Neutral, Dislike, Strongly Dislike), **Likeness_int** (this column contains the integer value for categorical values in Likeness column) and **Benchmark_A** (in this column we have determined whether the specific image is taken for training or testing).\n",
        "\n",
        "We have now described the attribute dataset that we will have to consider in order to design the prediction model.\n",
        "\n",
        "### 2. Preprocessing:\n",
        "\n",
        "Let us now load the dataset:\n",
        "        In order to load the dataset, we will make use of **google colab** and **google drive**. We will first make sure that we can access our google drive through google colab. To do so, we first created a seperate folder in our drive, and in that created another folder named 'Data', again created a folder inside 'Data', named 'MLEnd', and then we install the library 'mlend' as below."
      ],
      "metadata": {
        "id": "gb-6Cla98avj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlend"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "thJHFTIYYJvb",
        "outputId": "7f1213a1-1ff2-4900-d6d3-2b9add1d2037"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlend\n",
            "  Downloading mlend-1.0.0.3-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: numpy>1.8 in /usr/local/lib/python3.10/dist-packages (from mlend) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from mlend) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mlend) (1.11.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mlend) (3.7.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from mlend) (1.3.2)\n",
            "Collecting spkit>0.0.9.5 (from mlend)\n",
            "  Downloading spkit-0.0.9.6.7-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from spkit>0.0.9.5->mlend) (1.2.2)\n",
            "Collecting python-picard (from spkit>0.0.9.5->mlend)\n",
            "  Downloading python_picard-0.7-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from spkit>0.0.9.5->mlend) (1.5.0)\n",
            "Collecting pylfsr (from spkit>0.0.9.5->mlend)\n",
            "  Downloading pylfsr-1.0.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from spkit>0.0.9.5->mlend) (3.9.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from spkit>0.0.9.5->mlend) (0.12.2)\n",
            "Collecting phyaat (from spkit>0.0.9.5->mlend)\n",
            "  Downloading phyaat-0.0.3-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mlend) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mlend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mlend) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mlend) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mlend) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mlend) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mlend) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mlend) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->mlend) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mlend) (1.16.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from python-picard->spkit>0.0.9.5->mlend) (2.8.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->spkit>0.0.9.5->mlend) (3.2.0)\n",
            "Installing collected packages: python-picard, pylfsr, phyaat, spkit, mlend\n",
            "Successfully installed mlend-1.0.0.3 phyaat-0.0.3 pylfsr-1.0.7 python-picard-0.7 spkit-0.0.9.6.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will load the dataset. In order to do so, we will use different libraries and modules from **python**, and then mount our **google drive**."
      ],
      "metadata": {
        "id": "pgRvkdowaD_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import spkit as sp\n",
        "\n",
        "from skimage import exposure\n",
        "from skimage.color import rgb2hsv, rgb2gray\n",
        "import skimage as ski\n",
        "\n",
        "import mlend\n",
        "from mlend import download_yummy, yummy_load\n",
        "\n",
        "import os, sys, re, pickle, glob\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "import IPython.display as ipd\n",
        "from tqdm import tqdm\n",
        "import librosa\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ByRDmHFIaEv6",
        "outputId": "57a75ad7-fd30-4ea2-c983-0b00b8825e38"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will be loading the dataset:"
      ],
      "metadata": {
        "id": "ofVTbP7WaRit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subset = {}\n",
        "\n",
        "datadir = download_yummy(save_to = '/content/drive/MyDrive/Data/MLEnd', subset = subset,verbose=1,overwrite=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Fa_x4pekayL6",
        "outputId": "edeeee0b-2478-470f-d65c-8b7dd3f9b585"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 3250 image files from https://github.com/MLEndDatasets/Yummy\n",
            "100%|\u001b[0m▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\u001b[0m|3250\\3250|003250.jpg\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we are using **download_yummy** function to download the **MLEnd Yummy Dataset**. We have also saved it in a different directory.\n",
        "\n",
        "Our attributes of the dataset are text based, which is why we will be creating a CSV file to store those attributes. We will not be storing the Photo attribute in this file as it is complex to be stored in such a file. So, we store the images in a different folder, but the filename of each image is still stored in the CSV file."
      ],
      "metadata": {
        "id": "GiaNJROSb8v3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MLENDYD_df = pd.read_csv('/content/drive/MyDrive/Data/MLEnd/yummy/MLEndYD_image_attributes_benchmark.csv').set_index('filename')\n",
        "MLENDYD_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "zZeqvQgZcY5T",
        "outputId": "5388739d-5a2a-47f5-d6d7-a964dae801d3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      Diet Cuisine_org   Cuisine  \\\n",
              "filename                                           \n",
              "000001.jpg  non_vegetarian    japanese  japanese   \n",
              "000002.jpg  non_vegetarian     english   english   \n",
              "000003.jpg  non_vegetarian     chinese   chinese   \n",
              "000004.jpg      vegetarian      indian    indian   \n",
              "000005.jpg  non_vegetarian      indian    indian   \n",
              "...                    ...         ...       ...   \n",
              "003246.jpg      vegetarian      indian    indian   \n",
              "003247.jpg      vegetarian      indian    indian   \n",
              "003248.jpg      vegetarian      indian    indian   \n",
              "003249.jpg           vegan      indian    indian   \n",
              "003250.jpg  non_vegetarian    american  american   \n",
              "\n",
              "                                   Dish_name     Home_or_restaurant  \\\n",
              "filename                                                              \n",
              "000001.jpg                chicken_katsu_rice          marugame_udon   \n",
              "000002.jpg                 english_breakfast                   home   \n",
              "000003.jpg                     spicy_chicken  jinli_flagship_branch   \n",
              "000004.jpg                       gulab_jamun                   home   \n",
              "000005.jpg                    chicken_masala                   home   \n",
              "...                                      ...                    ...   \n",
              "003246.jpg                        zeera_rice                   home   \n",
              "003247.jpg                    paneer_and_dal                   home   \n",
              "003248.jpg                            samosa                   home   \n",
              "003249.jpg                        fruit_milk                   home   \n",
              "003250.jpg  beef_burger_with_onion_and_salad                   home   \n",
              "\n",
              "                                                  Ingredients  \\\n",
              "filename                                                        \n",
              "000001.jpg              rice,chicken_breast,spicy_curry_sauce   \n",
              "000002.jpg  eggs,bacon,hash_brown,tomato,bread,tomato,bake...   \n",
              "000003.jpg  chili,chicken,peanuts,sihuan_peppercorns,green...   \n",
              "000004.jpg      sugar,water,khoya,milk,salt,oil,cardamon,ghee   \n",
              "000005.jpg  chicken,lemon,turmeric,garam_masala,coriander_...   \n",
              "...                                                       ...   \n",
              "003246.jpg  1_cup_basmati_rice,2_cups_water,2_tablespoons_...   \n",
              "003247.jpg  fried_cottage_cheese,ghee,lentils,milk,wheat_f...   \n",
              "003248.jpg  potato,onion,peanut,salt,turmeric_powder,red_c...   \n",
              "003249.jpg                             kiwi,banana,apple,milk   \n",
              "003250.jpg   beef_patty,bread_roll,cherry_tomato,_onion,chive   \n",
              "\n",
              "           Healthiness_rating  Healthiness_rating_int       Likeness  \\\n",
              "filename                                                               \n",
              "000001.jpg            neutral                     3.0           like   \n",
              "000002.jpg          unhealthy                     2.0           like   \n",
              "000003.jpg            neutral                     3.0  strongly_like   \n",
              "000004.jpg          unhealthy                     2.0  strongly_like   \n",
              "000005.jpg            healthy                     4.0  strongly_like   \n",
              "...                       ...                     ...            ...   \n",
              "003246.jpg            healthy                     4.0  strongly_like   \n",
              "003247.jpg            healthy                     4.0  strongly_like   \n",
              "003248.jpg     very_unhealthy                     1.0           like   \n",
              "003249.jpg       very_healthy                     5.0  strongly_like   \n",
              "003250.jpg            neutral                     3.0           like   \n",
              "\n",
              "            Likeness_int Benchmark_A  \n",
              "filename                              \n",
              "000001.jpg           4.0       Train  \n",
              "000002.jpg           4.0       Train  \n",
              "000003.jpg           5.0       Train  \n",
              "000004.jpg           5.0       Train  \n",
              "000005.jpg           5.0       Train  \n",
              "...                  ...         ...  \n",
              "003246.jpg           5.0       Train  \n",
              "003247.jpg           5.0        Test  \n",
              "003248.jpg           4.0        Test  \n",
              "003249.jpg           5.0       Train  \n",
              "003250.jpg           4.0       Train  \n",
              "\n",
              "[3250 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9164d759-8215-40cb-bff4-50f7108044b6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Diet</th>\n",
              "      <th>Cuisine_org</th>\n",
              "      <th>Cuisine</th>\n",
              "      <th>Dish_name</th>\n",
              "      <th>Home_or_restaurant</th>\n",
              "      <th>Ingredients</th>\n",
              "      <th>Healthiness_rating</th>\n",
              "      <th>Healthiness_rating_int</th>\n",
              "      <th>Likeness</th>\n",
              "      <th>Likeness_int</th>\n",
              "      <th>Benchmark_A</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>filename</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>000001.jpg</th>\n",
              "      <td>non_vegetarian</td>\n",
              "      <td>japanese</td>\n",
              "      <td>japanese</td>\n",
              "      <td>chicken_katsu_rice</td>\n",
              "      <td>marugame_udon</td>\n",
              "      <td>rice,chicken_breast,spicy_curry_sauce</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3.0</td>\n",
              "      <td>like</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000002.jpg</th>\n",
              "      <td>non_vegetarian</td>\n",
              "      <td>english</td>\n",
              "      <td>english</td>\n",
              "      <td>english_breakfast</td>\n",
              "      <td>home</td>\n",
              "      <td>eggs,bacon,hash_brown,tomato,bread,tomato,bake...</td>\n",
              "      <td>unhealthy</td>\n",
              "      <td>2.0</td>\n",
              "      <td>like</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000003.jpg</th>\n",
              "      <td>non_vegetarian</td>\n",
              "      <td>chinese</td>\n",
              "      <td>chinese</td>\n",
              "      <td>spicy_chicken</td>\n",
              "      <td>jinli_flagship_branch</td>\n",
              "      <td>chili,chicken,peanuts,sihuan_peppercorns,green...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3.0</td>\n",
              "      <td>strongly_like</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000004.jpg</th>\n",
              "      <td>vegetarian</td>\n",
              "      <td>indian</td>\n",
              "      <td>indian</td>\n",
              "      <td>gulab_jamun</td>\n",
              "      <td>home</td>\n",
              "      <td>sugar,water,khoya,milk,salt,oil,cardamon,ghee</td>\n",
              "      <td>unhealthy</td>\n",
              "      <td>2.0</td>\n",
              "      <td>strongly_like</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000005.jpg</th>\n",
              "      <td>non_vegetarian</td>\n",
              "      <td>indian</td>\n",
              "      <td>indian</td>\n",
              "      <td>chicken_masala</td>\n",
              "      <td>home</td>\n",
              "      <td>chicken,lemon,turmeric,garam_masala,coriander_...</td>\n",
              "      <td>healthy</td>\n",
              "      <td>4.0</td>\n",
              "      <td>strongly_like</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>003246.jpg</th>\n",
              "      <td>vegetarian</td>\n",
              "      <td>indian</td>\n",
              "      <td>indian</td>\n",
              "      <td>zeera_rice</td>\n",
              "      <td>home</td>\n",
              "      <td>1_cup_basmati_rice,2_cups_water,2_tablespoons_...</td>\n",
              "      <td>healthy</td>\n",
              "      <td>4.0</td>\n",
              "      <td>strongly_like</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>003247.jpg</th>\n",
              "      <td>vegetarian</td>\n",
              "      <td>indian</td>\n",
              "      <td>indian</td>\n",
              "      <td>paneer_and_dal</td>\n",
              "      <td>home</td>\n",
              "      <td>fried_cottage_cheese,ghee,lentils,milk,wheat_f...</td>\n",
              "      <td>healthy</td>\n",
              "      <td>4.0</td>\n",
              "      <td>strongly_like</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>003248.jpg</th>\n",
              "      <td>vegetarian</td>\n",
              "      <td>indian</td>\n",
              "      <td>indian</td>\n",
              "      <td>samosa</td>\n",
              "      <td>home</td>\n",
              "      <td>potato,onion,peanut,salt,turmeric_powder,red_c...</td>\n",
              "      <td>very_unhealthy</td>\n",
              "      <td>1.0</td>\n",
              "      <td>like</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>003249.jpg</th>\n",
              "      <td>vegan</td>\n",
              "      <td>indian</td>\n",
              "      <td>indian</td>\n",
              "      <td>fruit_milk</td>\n",
              "      <td>home</td>\n",
              "      <td>kiwi,banana,apple,milk</td>\n",
              "      <td>very_healthy</td>\n",
              "      <td>5.0</td>\n",
              "      <td>strongly_like</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>003250.jpg</th>\n",
              "      <td>non_vegetarian</td>\n",
              "      <td>american</td>\n",
              "      <td>american</td>\n",
              "      <td>beef_burger_with_onion_and_salad</td>\n",
              "      <td>home</td>\n",
              "      <td>beef_patty,bread_roll,cherry_tomato,_onion,chive</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3.0</td>\n",
              "      <td>like</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3250 rows × 11 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9164d759-8215-40cb-bff4-50f7108044b6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9164d759-8215-40cb-bff4-50f7108044b6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9164d759-8215-40cb-bff4-50f7108044b6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f71e41b4-417c-43a2-ad01-d0239c7796eb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f71e41b4-417c-43a2-ad01-d0239c7796eb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f71e41b4-417c-43a2-ad01-d0239c7796eb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above are the contents of the CSV file. We can see that there are 3250 rows and 11 columns in our dataset, however, the cloumn **'filename'** acts as index and link to the image of the dish, which is why we have 12 columns. As we have already discussed, that we have cloumn **'Benchmark_A'**, in which we have determined whether the specific image is taken for training or testing. Using this column, let us divide the dataset into two different datasets, i.e. training and testing datasets. We will make the use of **yummy_load** function."
      ],
      "metadata": {
        "id": "B7jgNhLschGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the Basic Component of our project, we have used the in-built function **\"yummy_small_load\"** to load the dataset, by splitting it into train and test dataset and also mapping the values of **\"Rice\"** and **\"Chips\"** to **\"0\"** and **\"1\"** respectively. **But** here, we will have to customize the function in such a way that the **\"home\"** value of the **\"Home_or_restaurant\"** column is mapped to **\"0\"** and rest of all the values will be mapped to **\"1\"**. We also need the **\"Ingredients\"** column in order to design our problem statement. So, we will be customizing the **yummy_load** function as below:"
      ],
      "metadata": {
        "id": "CAmKzFpmn-gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split as sklearn_train_test_split\n",
        "\n",
        "def yummy_load(datadir_main='../MLEnd/yummy', train_test_split='Benchmark_A', verbose=1, encode_labels=True):\n",
        "\n",
        "    repo_path = 'https://github.com/MLEndDatasets/Yummy'\n",
        "    attributes_file_org = repo_path + '/raw/main/MLEndYD_image_attributes_benchmark.csv'\n",
        "\n",
        "    img_files = glob.glob(os.path.join(datadir_main, 'MLEndYD_images', '*.jpg'))\n",
        "    if verbose:\n",
        "        print(f'Total {len(img_files)} found in {os.path.join(datadir_main, \"MLEndYD_images\")}/')\n",
        "\n",
        "    attributes_file = os.path.join(datadir_main, 'MLEndYD_image_attributes_benchmark.csv')\n",
        "    if os.path.isfile(attributes_file):\n",
        "        D = pd.read_csv(attributes_file)\n",
        "    else:\n",
        "        D = pd.read_csv(attributes_file_org)\n",
        "\n",
        "    img_files_map = {file.split('/')[-1]: file for file in img_files}\n",
        "\n",
        "    Di = D.copy()\n",
        "\n",
        "    X_train_filepath = []\n",
        "    Y_train = []\n",
        "\n",
        "    X_test_filepath = []\n",
        "    Y_test = []\n",
        "\n",
        "    if isinstance(train_test_split, str):\n",
        "        if train_test_split in ['Benchmark_A']:\n",
        "            D_train = Di[Di[train_test_split] == 'Train']\n",
        "            D_test = Di[Di[train_test_split] == 'Test']\n",
        "        elif train_test_split.lower() == 'random':\n",
        "            Nt = int(Di.shape[0] * 0.7)\n",
        "            idx = [True] * Nt + [False] * (Di.shape[0] - Nt)\n",
        "            idx = np.array(idx)\n",
        "            np.random.shuffle(idx)\n",
        "            D_train = Di[idx]\n",
        "            D_test = Di[~idx]\n",
        "    elif isinstance(train_test_split, float) and 0 < train_test_split < 1:\n",
        "        Nt = int(Di.shape[0] * train_test_split)\n",
        "        idx = [True] * Nt + [False] * (Di.shape[0] - Nt)\n",
        "        idx = np.array(idx)\n",
        "        np.random.shuffle(idx)\n",
        "        D_train = Di[idx]\n",
        "        D_test = Di[~idx]\n",
        "    else:\n",
        "        raise ValueError(\"Invalid value for train_test_split. Should be str ['Benchmark_A', 'random'] or float (<1 and >0)\")\n",
        "\n",
        "    files_train = list(D_train['filename'])\n",
        "    X_train_filepath = [img_files_map[file] for file in files_train]\n",
        "    Y_train = np.array(D_train['Home_or_restaurant']).copy()\n",
        "\n",
        "    files_test = list(D_test['filename'])\n",
        "    X_test_filepath = [img_files_map[file] for file in files_test]\n",
        "    Y_test = np.array(list(D_test['Home_or_restaurant'])).copy()\n",
        "\n",
        "    TrainSet = {'X_paths': X_train_filepath, 'Y': Y_train, 'Ingredients': list(D_train['Ingredients'])}\n",
        "    TestSet = {'X_paths': X_test_filepath, 'Y': Y_test, 'Ingredients': list(D_test['Ingredients'])}\n",
        "\n",
        "    Y_train_enc = []\n",
        "    Y_test_enc = []\n",
        "    MAPs = {}\n",
        "\n",
        "    if encode_labels:\n",
        "        home_rest_map = {'home': 0}\n",
        "        y1 = Y_train[:].copy()\n",
        "        y2 = Y_test[:].copy()\n",
        "\n",
        "        unique_labels = list(set(y1) | set(y2))\n",
        "        unique_labels.sort()\n",
        "\n",
        "        for k, v in enumerate(unique_labels):\n",
        "            if v == 'home':\n",
        "                home_rest_map[v] = 0\n",
        "            else:\n",
        "                home_rest_map[v] = 1\n",
        "\n",
        "        Y_train_enc = np.array([home_rest_map[label] for label in y1])\n",
        "        Y_test_enc = np.array([home_rest_map[label] for label in y2])\n",
        "\n",
        "        MAPs = {'Home_or_restaurant': home_rest_map}\n",
        "\n",
        "        TrainSet['Y_encoded'] = Y_train_enc\n",
        "        TestSet['Y_encoded'] = Y_test_enc\n",
        "\n",
        "    return TrainSet, TestSet, MAPs\n"
      ],
      "metadata": {
        "id": "bbOOx9lUpR21"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TrainSet, TestSet, Map = yummy_load(datadir_main=datadir,train_test_split='Benchmark_A')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cGgsT5ScqF0k",
        "outputId": "0f0d8f8d-ef2d-4b70-e189-2993b26e0943"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 3250 found in /content/drive/MyDrive/Data/MLEnd/yummy/MLEndYD_images/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now describe how the train and test datasets are mapped with 0 and 1 instead of home and any other restaurant name."
      ],
      "metadata": {
        "id": "y5CJZXGdpytD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TrainSet.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "y5I2Idp7p9dc",
        "outputId": "32008ad3-2aaf-4c88-ffe2-c488b388e6e3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['X_paths', 'Y', 'Ingredients', 'Y_encoded'])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TestSet.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wqht7JKaqRgE",
        "outputId": "9542356d-a2be-46d0-bc63-ed99bc64afa1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['X_paths', 'Y', 'Ingredients', 'Y_encoded'])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "o0dKr1OZqaHM",
        "outputId": "e29a0c69-7684-4f7f-a65e-84c5788b4c6c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Home_or_restaurant': {'home': 0,\n",
              "  '36_street_food': 1,\n",
              "  'afghan_grill': 1,\n",
              "  'albura_kathisma_bistro': 1,\n",
              "  'aldi': 1,\n",
              "  'ambala': 1,\n",
              "  'anjappar_restaurant': 1,\n",
              "  'antalya_restaurant': 1,\n",
              "  'asda': 1,\n",
              "  'bamboo': 1,\n",
              "  'bananatree': 1,\n",
              "  \"bill's\": 1,\n",
              "  'biryani_house': 1,\n",
              "  'broasto': 1,\n",
              "  'bui_vien': 1,\n",
              "  'buns_&_berries': 1,\n",
              "  'burgasum': 1,\n",
              "  'burger_&_beyond': 1,\n",
              "  'burger_and_chop': 1,\n",
              "  'burgitzza_watford': 1,\n",
              "  'cafe_de_nata': 1,\n",
              "  'cake_box': 1,\n",
              "  'canting': 1,\n",
              "  'capital_restaurant': 1,\n",
              "  'chengdufu': 1,\n",
              "  'chicken_shop': 1,\n",
              "  'chicken_world': 1,\n",
              "  'chinese_supermarket': 1,\n",
              "  'chongqing_old_street': 1,\n",
              "  'co-op': 1,\n",
              "  'coco_di_mama': 1,\n",
              "  'costa': 1,\n",
              "  'curve': 1,\n",
              "  'dalchini': 1,\n",
              "  'dandan_noodle_restaurant': 1,\n",
              "  'dartmoor_lodge': 1,\n",
              "  'dashi_chazuke': 1,\n",
              "  'delamina_east': 1,\n",
              "  'desi_lounge': 1,\n",
              "  'dominos': 1,\n",
              "  'domino’s': 1,\n",
              "  'eat_tokyo': 1,\n",
              "  'efes': 1,\n",
              "  'efes_restaurant': 1,\n",
              "  \"emilia's_crafted_pasta\": 1,\n",
              "  'eminonu_borekcisi': 1,\n",
              "  'emirates_restaurant': 1,\n",
              "  'erhan': 1,\n",
              "  'fanzy': 1,\n",
              "  'farmer.j': 1,\n",
              "  \"ferrari's\": 1,\n",
              "  'five_guys': 1,\n",
              "  'five_guys_watford': 1,\n",
              "  'flames': 1,\n",
              "  'flat_iron': 1,\n",
              "  'fortitude_bakehouse': 1,\n",
              "  'fried_&_grilled': 1,\n",
              "  'gdk': 1,\n",
              "  'german_doner_kebab': 1,\n",
              "  'german_doner_kebab_watford': 1,\n",
              "  'gindaco': 1,\n",
              "  'gonpachi': 1,\n",
              "  'goodfellas': 1,\n",
              "  'grad_café': 1,\n",
              "  'green_pepper': 1,\n",
              "  'green_valley': 1,\n",
              "  'greggs': 1,\n",
              "  'grilled_cottage_watford': 1,\n",
              "  'ground_café,qmul': 1,\n",
              "  'haidilao_hotpot_london': 1,\n",
              "  'haldiram’s': 1,\n",
              "  'half_moon': 1,\n",
              "  'harman': 1,\n",
              "  \"harper's_steakhouse_weighbridge\": 1,\n",
              "  'harvester': 1,\n",
              "  'hiba': 1,\n",
              "  'hiba_restraunt': 1,\n",
              "  'home_(hellofresh)': 1,\n",
              "  'home_café': 1,\n",
              "  'homemade': 1,\n",
              "  'homies_on_donkies': 1,\n",
              "  'hong_kong_restaurant': 1,\n",
              "  'iceland': 1,\n",
              "  'itadakizen_london': 1,\n",
              "  'itsu': 1,\n",
              "  'jahan': 1,\n",
              "  'jinli': 1,\n",
              "  'jinli_flagship_branch': 1,\n",
              "  'joe_&_the_juice': 1,\n",
              "  'joe_and_the_juice': 1,\n",
              "  'jrc_global_buffet': 1,\n",
              "  'k.o_kebabish': 1,\n",
              "  \"kennedy's_fish_&_chips\": 1,\n",
              "  'kentucky_fried_chicken': 1,\n",
              "  'kfc': 1,\n",
              "  'khf': 1,\n",
              "  'khyber_grill': 1,\n",
              "  'kish_restaurant': 1,\n",
              "  'korean_street_food': 1,\n",
              "  'kujawiak': 1,\n",
              "  'lakers': 1,\n",
              "  'le_kitchen_vietnamese_restaurant': 1,\n",
              "  'leon': 1,\n",
              "  'lidl': 1,\n",
              "  'little_pizza_hicce': 1,\n",
              "  'm&s': 1,\n",
              "  'm&s_food_hall_euston_station': 1,\n",
              "  'm&s_simply_food': 1,\n",
              "  \"maamala's\": 1,\n",
              "  'mama_li': 1,\n",
              "  'mammala_restaurant': 1,\n",
              "  'maopao_mini_pot': 1,\n",
              "  'marugame_udon': 1,\n",
              "  'mauriyas_restaurant': 1,\n",
              "  \"mc_donald's\": 1,\n",
              "  'mc_donalds': 1,\n",
              "  'mcdonald': 1,\n",
              "  \"mcdonald's\": 1,\n",
              "  'mcdonalds': 1,\n",
              "  'mehak': 1,\n",
              "  'mexican_dining_otra': 1,\n",
              "  'mian': 1,\n",
              "  'morrisons': 1,\n",
              "  'mr._wu': 1,\n",
              "  'mr_wong’s_wok_&_box_️': 1,\n",
              "  \"mrs_chew's_chinese_kitchen\": 1,\n",
              "  'my_old_place': 1,\n",
              "  'naan_spitalfields': 1,\n",
              "  \"nando's\": 1,\n",
              "  \"nando's_euston_station\": 1,\n",
              "  'nandos': 1,\n",
              "  'nirala_sweets': 1,\n",
              "  'obento_deli': 1,\n",
              "  'ohba_leaf_japanese_kitchen_@_hackney': 1,\n",
              "  'old_building-lse': 1,\n",
              "  'oowee_diner': 1,\n",
              "  'papa_johns': 1,\n",
              "  'papa_nadox_kitchen': 1,\n",
              "  'pasty_shop_euston_station': 1,\n",
              "  'pilpel': 1,\n",
              "  'pizza_gogo': 1,\n",
              "  'pizza_hut': 1,\n",
              "  'pizza_room': 1,\n",
              "  'pizza_union': 1,\n",
              "  'pizzaexpress': 1,\n",
              "  'pizzahut': 1,\n",
              "  'pret_a_manger': 1,\n",
              "  'protein_pizzas': 1,\n",
              "  'qm_student_union_centre': 1,\n",
              "  'qmul_catering_service': 1,\n",
              "  'rairai_ken': 1,\n",
              "  'ramen_babaichiya_tomonojin': 1,\n",
              "  'resraurant': 1,\n",
              "  'restaurant': 1,\n",
              "  'restaurant(the_curve_-_starbucks)': 1,\n",
              "  'restaurant_(loon_fung_-stratford)': 1,\n",
              "  'restraurant': 1,\n",
              "  'restuarent': 1,\n",
              "  'resturant': 1,\n",
              "  'resturaunt': 1,\n",
              "  \"ronnie_scott's\": 1,\n",
              "  'roosters_piri_piri': 1,\n",
              "  \"rosa's\": 1,\n",
              "  \"rosa's_thai\": 1,\n",
              "  \"rosa's_thai_café\": 1,\n",
              "  'sainsbury': 1,\n",
              "  \"sainsbury's\": 1,\n",
              "  'sainsburys': 1,\n",
              "  \"sam's_chicken\": 1,\n",
              "  'san_carlo': 1,\n",
              "  'sarashina_horii': 1,\n",
              "  'saravana_bhavan': 1,\n",
              "  'senatus': 1,\n",
              "  'shake_shack': 1,\n",
              "  'shapur_restaurant': 1,\n",
              "  'shawarma': 1,\n",
              "  'sonargaon': 1,\n",
              "  'south_oxhey_fish_and_chips': 1,\n",
              "  'spag_bowl(bow)': 1,\n",
              "  'spice_hut': 1,\n",
              "  'subway': 1,\n",
              "  'sultanahmet_bufesi': 1,\n",
              "  'super_mario_emin_usta': 1,\n",
              "  'taco_bell': 1,\n",
              "  'taitussi': 1,\n",
              "  'tanpopo': 1,\n",
              "  'tasty_treats_restaurant': 1,\n",
              "  'tcr_bar': 1,\n",
              "  'tesco': 1,\n",
              "  'tesco_express': 1,\n",
              "  'the_curve': 1,\n",
              "  'the_curve_mile_end': 1,\n",
              "  'the_gourmet_hut': 1,\n",
              "  'the_pizza_room': 1,\n",
              "  'the_pure_food_co': 1,\n",
              "  'tiantian': 1,\n",
              "  'tonkotsu': 1,\n",
              "  'tortilla': 1,\n",
              "  'unagiya': 1,\n",
              "  'vasiniko': 1,\n",
              "  'wagamama': 1,\n",
              "  'waitrose': 1,\n",
              "  'wasabi': 1,\n",
              "  'wazzir': 1,\n",
              "  'wendys': 1,\n",
              "  'wetherspoons': 1,\n",
              "  'wicked_burgers': 1,\n",
              "  'wngz': 1,\n",
              "  'wok&box': 1,\n",
              "  'wok_&_box': 1,\n",
              "  'ymca_indian_restaurant': 1,\n",
              "  'you_me_sushi': 1,\n",
              "  'young_cheng_buffet': 1,\n",
              "  'yumpees': 1,\n",
              "  'yun_gui_chuan': 1}}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see in the above cell, the **\"home\"** value is mapped to **\"0\"** and rest of the values are mapped to **\"1\"**. We can now say that we have two classes. If we would not have done this, we would have had many different classes. You can see that there are also spelling mistakes which would have caused generation of extra unwanted classes."
      ],
      "metadata": {
        "id": "6VVFPGSVqdHy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now make a variable which will store the list of training **\"Ingredients\"**, training **\"Y_encoded\"**, which is nothing but the binary structure of the **\"Home_or_restaurant\"** column."
      ],
      "metadata": {
        "id": "jJPpuMQirYiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TrainSet_df = pd.DataFrame(TrainSet)\n",
        "TestSet_df = pd.DataFrame(TestSet)\n",
        "\n",
        "X_train = TrainSet_df['Ingredients']\n",
        "y_train = TrainSet_df['Y_encoded']\n",
        "\n",
        "X_test = TestSet_df['Ingredients']\n",
        "y_test = TestSet_df['Y_encoded']"
      ],
      "metadata": {
        "id": "QPV8XFEQsV6M"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whenever we are taking care of any problem statement, we should always make sure that we do not have any type of null values. Let us take care of them first."
      ],
      "metadata": {
        "id": "yLLdFYjSsZEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.fillna('')\n",
        "X_test = X_test.fillna('')"
      ],
      "metadata": {
        "id": "OARyPIuAso9a"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Feature Extraction OR Transformation Stage:\n",
        "\n",
        "Let us now extract the features using **CountVectorizer** in order to convert the collection of text that is **\"Ingredients\"** into a matrix of token counts. This is done so that we can convert the categorical values of ingredients into numerical format."
      ],
      "metadata": {
        "id": "AhXFxqQ4tWjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "pUkQt-DvuitX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Trianing OR Modelling:\n",
        "\n",
        "### Methodology:\n",
        "\n",
        "First we will train this data with the help of **Multinomial Naive Bayes model** algorithm and check for its accuracy."
      ],
      "metadata": {
        "id": "loL_AP38uoLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test_vectorized)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1d7fflUZuzGI",
        "outputId": "f496a6c2-b508-4899-b838-c7f3d5277e19"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 73.95%\n",
            "Confusion Matrix:\n",
            "[[588  65]\n",
            " [189 133]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.90      0.82       653\n",
            "           1       0.67      0.41      0.51       322\n",
            "\n",
            "    accuracy                           0.74       975\n",
            "   macro avg       0.71      0.66      0.67       975\n",
            "weighted avg       0.73      0.74      0.72       975\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**73.95% accuracy!!!**\n",
        "\n",
        "### 5. Prediction:\n",
        "\n",
        "Quite good, but let us check what it predicts for a label by giving it some input."
      ],
      "metadata": {
        "id": "Z4YLVCjIu9Fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_input_index = 17  # You can change this to any index in the test set\n",
        "input_test_data = X_test.iloc[[test_input_index]].values  # Get the input data for prediction\n",
        "actual_label = y_test.iloc[test_input_index]  # Get the actual label\n",
        "\n",
        "# Vectorize the input data\n",
        "input_test_vectorized = vectorizer.transform(input_test_data)\n",
        "\n",
        "# Make prediction\n",
        "predicted_label = model.predict(input_test_vectorized)[0]\n",
        "\n",
        "# Print ingredients and labels\n",
        "print(f\"Ingredients for Test Input {test_input_index}: {input_test_data[0]}\")\n",
        "print(f\"Actual Label: {'Home' if actual_label == 0 else 'Restaurant'}\")\n",
        "print(f\"Predicted Label: {'Home' if predicted_label == 0 else 'Restaurant'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5crSVbTLvNEW",
        "outputId": "19c0c5b5-3e81-46ab-d2ae-72f64aa09fbd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingredients for Test Input 17: chicken,oil,bread_crumbs,flour,egg,honey_and_garlic_sauce\n",
            "Actual Label: Restaurant\n",
            "Predicted Label: Home\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OHH**\n",
        "\n",
        "The actual and Predicted label for the second test data is not the same.\n",
        "\n",
        "**BUT**\n",
        "\n",
        "Have you noticed something?\n",
        "\n",
        "We can see that in the set of input ingredients, we have **\"honey_and_garlic_sauce\"**, which is usually not present at home, and hence the Actual Label says that the dish is made at a Restaurant."
      ],
      "metadata": {
        "id": "LcFCLl75vRWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let us try to predict the same using a different algorithm, say **Neural Networks**."
      ],
      "metadata": {
        "id": "TmeQ0SAVwBVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Convert lists to DataFrames\n",
        "TrainSet_df = pd.DataFrame(TrainSet)\n",
        "TestSet_df = pd.DataFrame(TestSet)\n",
        "\n",
        "# Handle missing values in the 'Ingredients' column for both training and test sets\n",
        "TrainSet_df['Ingredients'] = TrainSet_df['Ingredients'].fillna('')\n",
        "TestSet_df['Ingredients'] = TestSet_df['Ingredients'].fillna('')\n",
        "\n",
        "# One-hot encode the 'Ingredients' column for both training and test sets\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(TrainSet_df['Ingredients']).toarray()\n",
        "X_test_vectorized = vectorizer.transform(TestSet_df['Ingredients']).toarray()\n",
        "\n",
        "# Convert labels to numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(TrainSet_df['Y_encoded'])\n",
        "y_test_encoded = label_encoder.transform(TestSet_df['Y_encoded'])\n",
        "\n",
        "# Convert numerical labels to one-hot encoding\n",
        "y_train_categorical = to_categorical(y_train_encoded)\n",
        "y_test_categorical = to_categorical(y_test_encoded)\n",
        "\n",
        "# Build a simple neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_dim=X_train_vectorized.shape[1]))\n",
        "model.add(Dense(y_train_categorical.shape[1], activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_vectorized, y_train_categorical, epochs=5, batch_size=32)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test_vectorized, y_test_categorical)\n",
        "print(f\"Accuracy on Test Set: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "X0uwj7i0wNyN",
        "outputId": "c0a03d0e-afb6-4f0b-ca36-b2d1ebf3d77b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.5666 - accuracy: 0.7033\n",
            "Epoch 2/5\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.4203 - accuracy: 0.8273\n",
            "Epoch 3/5\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.3079 - accuracy: 0.8752\n",
            "Epoch 4/5\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.2213 - accuracy: 0.9253\n",
            "Epoch 5/5\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.1668 - accuracy: 0.9433\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 0.5981 - accuracy: 0.7436\n",
            "Accuracy on Test Set: 74.36%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even better. Let us check the value predicted for the same test data."
      ],
      "metadata": {
        "id": "xAU5f0n8w-xM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_input_index = 17\n",
        "input_test_data = TestSet_df['Ingredients'].iloc[test_input_index]\n",
        "actual_label = TestSet_df['Y_encoded'].iloc[test_input_index]\n",
        "\n",
        "input_test_vectorized = vectorizer.transform([input_test_data]).toarray()\n",
        "\n",
        "# Make a prediction on the single input\n",
        "y_pred_categorical = model.predict(input_test_vectorized)\n",
        "\n",
        "# Convert predicted labels from one-hot encoding to numerical labels\n",
        "y_pred_encoded = y_pred_categorical.argmax(axis=1)\n",
        "\n",
        "# Convert numerical labels to original labels\n",
        "predicted_label = label_encoder.inverse_transform(y_pred_encoded)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test_vectorized, y_test_categorical)\n",
        "print(f\"Ingredients: {input_test_data}\")\n",
        "print(f\"Actual Label: {'Home' if actual_label == 0 else 'Restaurant'}\")\n",
        "print(f\"Predicted Label: {'Home' if predicted_label == 'home' else 'Restaurant'}\")\n",
        "print(f\"Accuracy on Test Set: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "b6KUJsgAxKdl",
        "outputId": "ee9b1bb2-f94f-4423-dffc-2a89eed571c0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 121ms/step\n",
            "31/31 [==============================] - 0s 5ms/step - loss: 0.5981 - accuracy: 0.7436\n",
            "Ingredients: chicken,oil,bread_crumbs,flour,egg,honey_and_garlic_sauce\n",
            "Actual Label: Restaurant\n",
            "Predicted Label: Restaurant\n",
            "Accuracy on Test Set: 74.36%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-265c9cbb67e3>:20: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Great**\n",
        "\n",
        "We can see that the label is predicted correctly."
      ],
      "metadata": {
        "id": "9A5nRhIFxRZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "\n",
        "You can train and test more models using different algorithms. We can also add new features in the feature extraction part, so that we can acheive more accuracy for both training and testing datasets."
      ],
      "metadata": {
        "id": "7Ig9cbj01v3J"
      }
    }
  ]
}